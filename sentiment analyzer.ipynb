{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "311de401",
   "metadata": {},
   "source": [
    "# Twitter Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3a77432",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/jocellegonzales/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import tweepy\n",
    "from tweepy import OAuthHandler\n",
    "from textblob import TextBlob\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re \n",
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "import io\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4d74307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# API keys and tokens\n",
    "consumer_key = \"1oXtkBpLdErIe1brgMT2Gvn6b\"\n",
    "consumer_secret = \"LT9GdsIhDl9luNE5lG1KDuITyerBMkJyJljSybZ41GYCr6U5g3\"\n",
    "access_token = \"1526155687608594432-HNI9l5Ej8Vc5kbnFt8SgZH6c2Ycm9N\"\n",
    "access_token_secret = \"KXFjY6R3HCNM7OfklXYuCxImPEBg5GfeTOPFef64H4xYz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a70a5e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authenticate to twitter API\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "\n",
    "client = tweepy.API(auth, wait_on_rate_limit = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2ea4271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for removing unnecessary details from tweets\n",
    "def clean_data(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(\"@[\\w]*\", \"\", text)\n",
    "    text = re.sub(\"http\\S+\", \"\", text)\n",
    "    text = re.sub(\"[^a-zA-Z#]\", \" \", text)\n",
    "    text = re.sub(\"#\", \"\", text)\n",
    "    text = re.sub(\"rt\", \"\", text)\n",
    "    text = re.sub(\"\\s+\", \" \", text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "411abc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for calculating polarity\n",
    "def get_polarity(text):\n",
    "    return TextBlob(text).sentiment.polarity\n",
    "\n",
    "# Function for calculating subjectivity\n",
    "def get_subjectivity(text):\n",
    "    return TextBlob(text).sentiment.subjectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e7c6be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for categorizing sentiment of tweet\n",
    "def get_analysis(score):\n",
    "    if score < 0:\n",
    "        return \"Negative\"\n",
    "    if score == 0:\n",
    "        return \"Neutral\"\n",
    "    else:\n",
    "        return \"Positive\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "487546d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Widgets for input\n",
    "keyword=widgets.Text(\n",
    "    placeholder='Type something',\n",
    "    description='Keyword:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "number=widgets.Text(\n",
    "    placeholder='Number of tweets',\n",
    "    description='Count:',\n",
    "    disabled=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19fef8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Widgets for output\n",
    "generate_scores = widgets.Button(description=\"Generate\")\n",
    "output = widgets.Output()\n",
    "pie_output = widgets.Output()\n",
    "scatter_output = widgets.Output()\n",
    "word_output = widgets.Output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08bf56ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "@output.capture()\n",
    "# When user clicks the search button, it grabs tweets matching the keyword\n",
    "# and then generates a list containing their polarity score and sentiment\n",
    "def on_button_clicked(b):\n",
    "    output.clear_output()\n",
    "    pie_output.clear_output()\n",
    "    scatter_output.clear_output()\n",
    "    word_output.clear_output()\n",
    "    \n",
    "    tweets = client.search_tweets(keyword.value, count=number.value, lang=\"en\")\n",
    "    df = pd.DataFrame( [tweet.text for tweet in tweets] , columns=['Tweets'])\n",
    "    df['Tweets'] = df['Tweets'].apply(clean_data)\n",
    "    df['Polarity'] = df['Tweets'].apply(get_polarity) \n",
    "    df['Analysis'] = df['Polarity'].apply(get_analysis)\n",
    "    \n",
    "    # Calculate percentage of positive tweets\n",
    "    pos_tweets = df[df.Analysis == 'Positive']\n",
    "    \n",
    "    pos_percentage = round( (pos_tweets.shape[0]/df.shape[0])*100, 1)\n",
    "    \n",
    "    # Calculate percentage of negative tweets\n",
    "    neg_tweets = df[df.Analysis == 'Negative']\n",
    "    \n",
    "    neg_percentage = round( (neg_tweets.shape[0]/df.shape[0])*100, 1)\n",
    "    \n",
    "    print(\"Positive percentage = \", pos_percentage, '%')\n",
    "    print(\"Negative percentage = \", neg_percentage, '%')\n",
    "    print(df)\n",
    "    \n",
    "    # Plot pie chart\n",
    "    with pie_output:\n",
    "        positive = 0\n",
    "        negative = 0\n",
    "        neutral = 0\n",
    "\n",
    "        for p in df['Analysis']:\n",
    "            if p == 'Positive':\n",
    "                positive += 1\n",
    "            elif p == 'Negative':\n",
    "                negative += 1\n",
    "            else:\n",
    "                neutral += 1\n",
    "        \n",
    "        sizes = [positive, neutral, negative]\n",
    "        colors = ['yellowgreen', 'gold', 'red']\n",
    "        labels = ['Positive', 'Neutral', 'Negative']\n",
    "        plt.figure(figsize=(12,8)) \n",
    "        pie_chart=plt.pie(sizes, colors=colors, labels=labels, autopct='%1.1f%%')\n",
    "        plt.title(\"Sentiment Analysis\")\n",
    "        plt.show()\n",
    "        \n",
    "    # Plot scatterplot\n",
    "    with scatter_output:\n",
    "        plt.figure(figsize=(8,6))\n",
    "        df['Subjectivity'] = df['Tweets'].apply(get_subjectivity) \n",
    "        for i in range(0, df.shape[0]):\n",
    "            plt.scatter(df['Polarity'][i], df['Subjectivity'][i], color='Blue')\n",
    "            \n",
    "        plt.title(\"Sentiment Analysis\")\n",
    "        plt.xlabel('Polarity')\n",
    "        plt.ylabel('Subjectivity')\n",
    "        plt.show()\n",
    "        \n",
    "    # Plot word frequency bar graph\n",
    "    with word_output:\n",
    "        # Split tweets\n",
    "        split_tweets = str(df['Tweets']).split()\n",
    "        \n",
    "        cleaned_tweets = []\n",
    "        \n",
    "        filtered_tweets = []\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "        # Remove stopwords\n",
    "        for w in split_tweets: \n",
    "            if not w in stop_words and w != '...': \n",
    "                filtered_tweets.append(w)\n",
    "                \n",
    "        # Get 10 most common words\n",
    "        counter = Counter(filtered_tweets)\n",
    "        most_occur = counter.most_common(10) \n",
    "        \n",
    "        x1 = [x[0] for x in most_occur]\n",
    "        y1 = [x[1] for x in most_occur]\n",
    "        \n",
    "        # Plot bar graph\n",
    "        plt.figure(figsize=(10,6)) \n",
    "        plt.barh(x1, y1)\n",
    "        plt.title(\"Word Frequency Analysis\")\n",
    "        plt.xlabel('Frequency')\n",
    "        plt.ylabel('Words')\n",
    "        plt.show()\n",
    "    \n",
    "generate_scores.on_click(on_button_clicked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12158c89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95f53725e4d5472eb772c7a30bb0e06d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Text(value='', description='Keyword:', placeholder='Type something'), Text(valueâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4cd8f28fb714b3888f5a2fb61177f85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Generate', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display dashboard and widgets\n",
    "search_widgets = widgets.HBox( [keyword, number] )\n",
    "\n",
    "tabs = widgets.Tab([output, pie_output, scatter_output, word_output])\n",
    "tabs.set_title(0, 'Dataset')\n",
    "tabs.set_title(1, 'Pie Chart')\n",
    "tabs.set_title(2, 'Scatterplot')\n",
    "tabs.set_title(3, 'Word Frequency')\n",
    "dashboard = widgets.VBox([search_widgets, tabs])\n",
    "display(dashboard)\n",
    "display(generate_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c61434",
   "metadata": {},
   "source": [
    "# Manga Tag Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6ac269",
   "metadata": {},
   "outputs": [],
   "source": [
    "label1 = widgets.HTML(value='<p>We can perform sentiment analysis on a popular keyword, \"Manga\". Many artists use this to tag their work.</p>')\n",
    "label2 = widgets.HTML(value='<p>This a pie chart showing the percentage of positive, negative, and neutral tweets.</p>')\n",
    "\n",
    "display(label1)\n",
    "display(label2)\n",
    "\n",
    "dummy_tweets = client.search_tweets(\"Manga\", count=50, lang=\"en\")\n",
    "dataset = pd.DataFrame( [tweet.text for tweet in dummy_tweets] , columns=['Tweets'])\n",
    "dataset['Tweets'] = dataset['Tweets'].apply(clean_data)\n",
    "dataset['Polarity'] = dataset['Tweets'].apply(get_polarity) \n",
    "dataset['Subjectivity'] = dataset['Tweets'].apply(get_subjectivity) \n",
    "dataset['Analysis'] = dataset['Polarity'].apply(get_analysis)\n",
    "\n",
    "positive = 0\n",
    "negative = 0\n",
    "neutral = 0\n",
    "\n",
    "for p in dataset['Analysis']:\n",
    "    if p == 'Positive':\n",
    "        positive += 1\n",
    "    elif p == 'Negative':\n",
    "        negative += 1\n",
    "    else:\n",
    "        neutral += 1\n",
    "        \n",
    "sizes = [positive, neutral, negative]\n",
    "colors = ['yellowgreen', 'gold', 'red']\n",
    "labels = ['Positive', 'Neutral', 'Negative']\n",
    "plt.figure(figsize=(12,9)) \n",
    "piechart=plt.pie(sizes, colors=colors, labels=labels, autopct='%1.1f%%')\n",
    "plt.title(\"Manga Sentiment Analysis\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927954d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "label3 = widgets.HTML(value='<p>Here is a scatterplot showing the relationship between the subjectivity and polarity of manga tweets.</p>')\n",
    "\n",
    "display(label3)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "for i in range(0, dataset.shape[0]):\n",
    "    plt.scatter(dataset['Polarity'][i], dataset['Subjectivity'][i], color='Blue')\n",
    "plt.title(\"Manga Sentiment Analysis\")\n",
    "plt.xlabel('Polarity')\n",
    "plt.ylabel('Subjectivity')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5935c7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "label4 = widgets.HTML(value='<p>Finally, here is a bar graph showing the 10 most common words that appear under the Manga search query.</p>')\n",
    "\n",
    "display(label4)\n",
    "\n",
    "split_tweets = str(dataset['Tweets']).split()\n",
    "        \n",
    "cleaned_tweets = []\n",
    "        \n",
    "filtered_tweets = []\n",
    "stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "        \n",
    "for w in split_tweets: \n",
    "    if not w in stop_words and w != '...': \n",
    "        filtered_tweets.append(w)\n",
    "                \n",
    "counter = Counter(filtered_tweets)\n",
    "most_occur = counter.most_common(10) \n",
    "        \n",
    "x1 = [x[0] for x in most_occur]\n",
    "y1 = [x[1] for x in most_occur]\n",
    "        \n",
    "plt.figure(figsize=(10,6)) \n",
    "plt.barh(x1, y1)\n",
    "plt.title(\"Manga Word Frequency Analysis\")\n",
    "plt.xlabel('Frequency')\n",
    "plt.ylabel('Words')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb8989c",
   "metadata": {},
   "source": [
    "# Model Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbcf0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_count = 0\n",
    "pos_correct = 0\n",
    "\n",
    "with io.open('positive.txt', encoding='latin-1') as f:\n",
    "    for sample in f.read().split('\\n'):\n",
    "        if get_polarity(sample) > 0:\n",
    "            pos_correct += 1\n",
    "        pos_count +=1\n",
    "\n",
    "\n",
    "neg_count = 0\n",
    "neg_correct = 0\n",
    "\n",
    "with io.open('negative.txt', encoding='latin-1') as f:\n",
    "    for sample in f.read().split('\\n'):\n",
    "        if get_polarity(sample) <= 0:\n",
    "            neg_correct += 1\n",
    "        neg_count +=1\n",
    "\n",
    "print(\"Positive accuracy = {}% via {} samples\".format(round((pos_correct/pos_count*100.0), 1), pos_count))\n",
    "print(\"Negative accuracy = {}% via {} samples\".format(round((neg_correct/neg_count*100.0), 1), neg_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db45b10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
